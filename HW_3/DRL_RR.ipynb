{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24412,"status":"ok","timestamp":1699893716135,"user":{"displayName":"YUANJING ZHU","userId":"04814336122574376139"},"user_tz":300},"id":"43PcjF4xEzVC","outputId":"39deabbc-ff75-400a-c88f-267375a8a749"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle\n","data\t\t      __pycache__\t\t     SASRecModules.py\t\tsplit_data.py\n","DQN_NS.py\t      replay_buffer.py\t\t     SNQN_new.py\t\ttest.py\n","NextItNetModules.py   report_SNQN.txt\t\t     SNQN.py\t\t\tutility.py\n","pop.py\t\t      report_SNQN_with_Features.txt  SNQN_with_Features_new.py\n","preprocess_kaggle.py  SA2C.py\t\t\t     SNQN_with_Features.py\n"]}],"source":["# Mount Google Drive folder\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","PROJ_DIR = '/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle'\n","# change current directory after mounting\n","%cd $PROJ_DIR\n","! ls"]},{"cell_type":"markdown","metadata":{"id":"Gmu5H-KAFLol"},"source":["### Without features"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5117,"status":"ok","timestamp":1699893794189,"user":{"displayName":"YUANJING ZHU","userId":"04814336122574376139"},"user_tz":300},"id":"psbhE6ePEzVE","outputId":"d3436956-5be3-4add-b82f-b54d053190cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-11-13 16:43:09.432351: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-13 16:43:09.432405: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-13 16:43:09.432442: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-13 16:43:09.439767: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-11-13 16:43:10.467686: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","INFO line 99:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 102:13: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n","INFO line 104:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 107:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","WARNING line 112:29: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","INFO line 117:46: Renamed 'tf.nn.dynamic_rnn' to 'tf.compat.v1.nn.dynamic_rnn'\n","INFO line 118:20: Renamed 'tf.contrib.rnn.GRUCell' to 'tf.compat.v1.nn.rnn_cell.GRUCell'\n","INFO line 126:20: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n","INFO line 137:25: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n","\n","INFO line 137:25: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n","INFO line 141:28: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n","INFO line 145:31: Added keywords to args of function 'tf.nn.conv2d'\n","INFO line 145:31: Renamed keyword argument for tf.nn.conv2d from filter to filters\n","INFO line 157:33: Added keywords to args of function 'tf.nn.max_pool'\n","INFO line 157:33: Renamed keyword argument for tf.nn.max_pool from value to input\n","INFO line 157:33: Renamed 'tf.nn.max_pool' to 'tf.nn.max_pool2d'\n","INFO line 173:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n","\n","INFO line 173:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n","INFO line 176:24: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n","INFO line 179:27: Added keywords to args of function 'tf.nn.conv2d'\n","INFO line 179:27: Renamed keyword argument for tf.nn.conv2d from filter to filters\n","INFO line 193:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n","\n","INFO line 193:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n","INFO line 194:41: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n","INFO line 201:20: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n","WARNING line 218:36: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","WARNING line 239:26: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","INFO line 249:20: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n","INFO line 252:27: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n","INFO line 262:25: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n","INFO line 296:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 298:36: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 300:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 301:37: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 304:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 305:28: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 307:36: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 308:44: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 344:23: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n","INFO line 349:17: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n","INFO line 351:20: Renamed 'tf.random_normal' to 'tf.random.normal'\n","INFO line 355:20: Renamed 'tf.random_normal' to 'tf.random.normal'\n","INFO line 469:4: Renamed 'tf.reset_default_graph' to 'tf.compat.v1.reset_default_graph'\n","INFO line 492:9: Renamed 'tf.Session' to 'tf.compat.v1.Session'\n","INFO line 494:17: Renamed 'tf.global_variables_initializer' to 'tf.compat.v1.global_variables_initializer'\n","TensorFlow 2.0 Upgrade Script\n","-----------------------------\n","Converted 1 files\n","Detected 3 issues that require attention\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","File: /content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN.py\n","--------------------------------------------------------------------------------\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN.py:112:29: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN.py:218:36: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN.py:239:26: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","\n","\n","Make sure to read the detailed log 'report_SNQN.txt'\n","\n"]}],"source":["!tf_upgrade_v2 \\\n","  --infile '/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN.py' \\\n","  --outfile '/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_new.py' \\\n","  --reportfile report_SNQN.txt"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5129,"status":"ok","timestamp":1699893801510,"user":{"displayName":"YUANJING ZHU","userId":"04814336122574376139"},"user_tz":300},"id":"VEs70tUsEzVF","outputId":"9b543b8a-b5a8-44a1-e4b4-efcf9e978be7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Collecting trfl\n","  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n","Installing collected packages: trfl\n","Successfully installed trfl-1.2.0\n"]}],"source":["! pip install pandas trfl"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fWPw3MdJEzVG","outputId":"acf6e94e-5fdb-40ca-e10b-5fa33e0e437f"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-10-30 00:31:36.534670: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-10-30 00:31:36.534736: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-10-30 00:31:36.534769: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-10-30 00:31:36.543025: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-10-30 00:31:38.403964: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_new.py:118: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n","  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n","WARNING:tensorflow:From /content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_new.py:117: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_new.py:287: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_new.py:291: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2 = tf.compat.v1.layers.dense(\n","2023-10-30 00:31:52.482348: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 1.800000\n","clicks hr ndcg @ 5 : 0.000034, 0.000017\n","purchase hr and ndcg @5 : 0.000189, 0.000095\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 4.600000\n","clicks hr ndcg @ 10 : 0.000110, 0.000042\n","purchase hr and ndcg @10 : 0.000378, 0.000162\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 7.400000\n","clicks hr ndcg @ 15 : 0.000186, 0.000062\n","purchase hr and ndcg @15 : 0.000567, 0.000209\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 8.600000\n","clicks hr ndcg @ 20 : 0.000237, 0.000074\n","purchase hr and ndcg @20 : 0.000567, 0.000209\n","#############################################################\n","the loss in 200th batch is: 10.822102\n","the loss in 400th batch is: 10.737899\n","the loss in 600th batch is: 10.449997\n","the loss in 800th batch is: 10.326502\n","the loss in 1000th batch is: 10.548611\n","the loss in 1200th batch is: 10.269095\n","the loss in 1400th batch is: 10.029675\n","the loss in 1600th batch is: 9.871142\n","the loss in 1800th batch is: 9.655025\n","the loss in 2000th batch is: 9.567393\n","the loss in 2200th batch is: 9.667980\n","the loss in 2400th batch is: 9.537589\n","the loss in 2600th batch is: 9.202129\n","the loss in 2800th batch is: 9.061296\n","the loss in 3000th batch is: 9.278266\n","the loss in 3200th batch is: 9.104185\n","the loss in 3400th batch is: 8.894798\n","the loss in 3600th batch is: 8.970165\n","the loss in 3800th batch is: 8.756960\n","the loss in 4000th batch is: 8.397826\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 5910.600000\n","clicks hr ndcg @ 5 : 0.168867, 0.134118\n","purchase hr and ndcg @5 : 0.361935, 0.313384\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 6831.200000\n","clicks hr ndcg @ 10 : 0.199787, 0.144117\n","purchase hr and ndcg @10 : 0.397656, 0.324967\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 7368.000000\n","clicks hr ndcg @ 15 : 0.217740, 0.148867\n","purchase hr and ndcg @15 : 0.418824, 0.330604\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 7736.000000\n","clicks hr ndcg @ 20 : 0.230293, 0.151829\n","purchase hr and ndcg @20 : 0.432243, 0.333782\n","#############################################################\n","the loss in 4200th batch is: 8.820208\n","the loss in 4400th batch is: 8.202002\n","the loss in 4600th batch is: 8.327278\n","the loss in 4800th batch is: 8.178648\n","the loss in 5000th batch is: 8.025461\n","the loss in 5200th batch is: 7.828067\n","the loss in 5400th batch is: 7.778759\n","the loss in 5600th batch is: 7.847696\n","the loss in 5800th batch is: 7.933390\n","the loss in 6000th batch is: 7.680111\n","the loss in 6200th batch is: 7.616936\n","the loss in 6400th batch is: 7.714188\n","the loss in 6600th batch is: 7.660522\n","the loss in 6800th batch is: 8.006905\n","the loss in 7000th batch is: 7.616169\n","the loss in 7200th batch is: 7.193417\n","the loss in 7400th batch is: 7.303314\n","the loss in 7600th batch is: 7.168448\n","the loss in 7800th batch is: 7.534035\n","the loss in 8000th batch is: 7.354769\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 7981.400000\n","clicks hr ndcg @ 5 : 0.231113, 0.182808\n","purchase hr and ndcg @5 : 0.474957, 0.408043\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 9207.800000\n","clicks hr ndcg @ 10 : 0.273139, 0.196456\n","purchase hr and ndcg @10 : 0.518806, 0.422326\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 9899.400000\n","clicks hr ndcg @ 15 : 0.297424, 0.202890\n","purchase hr and ndcg @15 : 0.540919, 0.428172\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 10364.400000\n","clicks hr ndcg @ 20 : 0.313949, 0.206796\n","purchase hr and ndcg @20 : 0.554905, 0.431472\n","#############################################################\n","the loss in 8200th batch is: 7.357969\n","the loss in 8400th batch is: 6.915626\n","the loss in 8600th batch is: 6.624588\n","the loss in 8800th batch is: 6.566462\n"]}],"source":["# ! python SNQN_new.py --model=GRU --epoch=5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tcP0M52LFVGC","outputId":"c8dc1622-ba6d-4970-c770-71821f1e2dcd"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-10-31 14:15:40.360045: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-10-31 14:15:40.360124: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-10-31 14:15:40.360164: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-10-31 14:15:40.368179: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-10-31 14:15:42.064854: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_new.py:118: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n","  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n","WARNING:tensorflow:From /content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_new.py:117: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_new.py:287: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_new.py:291: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2 = tf.compat.v1.layers.dense(\n","2023-10-31 14:15:54.609221: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 1.000000\n","clicks hr ndcg @ 5 : 0.000042, 0.000030\n","purchase hr and ndcg @5 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 2.200000\n","clicks hr ndcg @ 10 : 0.000093, 0.000046\n","purchase hr and ndcg @10 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 3.400000\n","clicks hr ndcg @ 15 : 0.000144, 0.000059\n","purchase hr and ndcg @15 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 5.000000\n","clicks hr ndcg @ 20 : 0.000211, 0.000075\n","purchase hr and ndcg @20 : 0.000000, 0.000000\n","#############################################################\n","the loss in 200th batch is: 10.968710\n","the loss in 400th batch is: 10.736464\n","the loss in 600th batch is: 10.519002\n","the loss in 800th batch is: 10.245086\n","the loss in 1000th batch is: 10.303394\n","the loss in 1200th batch is: 10.335072\n","the loss in 1400th batch is: 9.969818\n","the loss in 1600th batch is: 9.962059\n","the loss in 1800th batch is: 9.675186\n","the loss in 2000th batch is: 9.479929\n","the loss in 2200th batch is: 9.106692\n","the loss in 2400th batch is: 9.294588\n","the loss in 2600th batch is: 9.437807\n","the loss in 2800th batch is: 9.376711\n","the loss in 3000th batch is: 9.051457\n","the loss in 3200th batch is: 9.070852\n","the loss in 3400th batch is: 8.907870\n","the loss in 3600th batch is: 8.952232\n","the loss in 3800th batch is: 8.532639\n","the loss in 4000th batch is: 8.562676\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 5989.600000\n","clicks hr ndcg @ 5 : 0.171403, 0.135156\n","purchase hr and ndcg @5 : 0.365526, 0.312241\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 6937.200000\n","clicks hr ndcg @ 10 : 0.203168, 0.145433\n","purchase hr and ndcg @10 : 0.402570, 0.324409\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 7483.600000\n","clicks hr ndcg @ 15 : 0.221569, 0.150310\n","purchase hr and ndcg @15 : 0.423549, 0.329951\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 7867.200000\n","clicks hr ndcg @ 20 : 0.234232, 0.153302\n","purchase hr and ndcg @20 : 0.439425, 0.333716\n","#############################################################\n","the loss in 4200th batch is: 8.698386\n","the loss in 4400th batch is: 8.317193\n","the loss in 4600th batch is: 8.829404\n","the loss in 4800th batch is: 8.321703\n","the loss in 5000th batch is: 8.302218\n","the loss in 5200th batch is: 8.234598\n","the loss in 5400th batch is: 8.368305\n","the loss in 5600th batch is: 8.337954\n","the loss in 5800th batch is: 7.532579\n","the loss in 6000th batch is: 7.273517\n","the loss in 6200th batch is: 7.748407\n","the loss in 6400th batch is: 7.900403\n","the loss in 6600th batch is: 7.481434\n","the loss in 6800th batch is: 7.340713\n","the loss in 7000th batch is: 7.554637\n","the loss in 7200th batch is: 7.198985\n","the loss in 7400th batch is: 7.248625\n","the loss in 7600th batch is: 6.956857\n","the loss in 7800th batch is: 7.394851\n"]}],"source":["# ! python SNQN_new.py --model=GRU --epoch=5"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"pL5755OhFVD3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bb8d042b-e12c-4368-8ebb-348c7b5de39b","executionInfo":{"status":"ok","timestamp":1699838250124,"user_tz":300,"elapsed":3041291,"user":{"displayName":"YUANJING ZHU","userId":"04814336122574376139"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-11-12 23:24:35.970672: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-11-12 23:24:36.014281: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-12 23:24:36.014326: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-12 23:24:36.014369: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-12 23:24:36.022621: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-11-12 23:24:37.137340: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_new.py:118: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n","  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n","WARNING:tensorflow:From /content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_new.py:117: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","2023-11-12 23:24:44.744255: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-11-12 23:24:44.744426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38350 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_new.py:287: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_new.py:291: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2 = tf.compat.v1.layers.dense(\n","2023-11-12 23:24:52.303386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38350 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n","2023-11-12 23:24:52.327625: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 1.600000\n","clicks hr ndcg @ 5 : 0.000068, 0.000036\n","purchase hr and ndcg @5 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 2.400000\n","clicks hr ndcg @ 10 : 0.000101, 0.000047\n","purchase hr and ndcg @10 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 3.200000\n","clicks hr ndcg @ 15 : 0.000135, 0.000056\n","purchase hr and ndcg @15 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 5.000000\n","clicks hr ndcg @ 20 : 0.000211, 0.000074\n","purchase hr and ndcg @20 : 0.000000, 0.000000\n","#############################################################\n","the loss in 200th batch is: 10.897139\n","the loss in 400th batch is: 10.616472\n","the loss in 600th batch is: 10.569795\n","the loss in 800th batch is: 10.441313\n","the loss in 1000th batch is: 9.937887\n","the loss in 1200th batch is: 10.320928\n","the loss in 1400th batch is: 10.223109\n","the loss in 1600th batch is: 10.024332\n","the loss in 1800th batch is: 10.027375\n","the loss in 2000th batch is: 9.827157\n","the loss in 2200th batch is: 10.057050\n","the loss in 2400th batch is: 9.301947\n","the loss in 2600th batch is: 9.347925\n","the loss in 2800th batch is: 9.564158\n","the loss in 3000th batch is: 9.486919\n","the loss in 3200th batch is: 9.043161\n","the loss in 3400th batch is: 8.901508\n","the loss in 3600th batch is: 9.039857\n","the loss in 3800th batch is: 8.766648\n","the loss in 4000th batch is: 7.906079\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 5931.800000\n","clicks hr ndcg @ 5 : 0.170439, 0.134066\n","purchase hr and ndcg @5 : 0.358911, 0.304986\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 6821.800000\n","clicks hr ndcg @ 10 : 0.200320, 0.143732\n","purchase hr and ndcg @10 : 0.393498, 0.316158\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 7370.600000\n","clicks hr ndcg @ 15 : 0.218484, 0.148546\n","purchase hr and ndcg @15 : 0.415989, 0.322085\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 7751.000000\n","clicks hr ndcg @ 20 : 0.231518, 0.151627\n","purchase hr and ndcg @20 : 0.429597, 0.325306\n","#############################################################\n","the loss in 4200th batch is: 8.730808\n","the loss in 4400th batch is: 8.320932\n","the loss in 4600th batch is: 8.319307\n","the loss in 4800th batch is: 8.243090\n","the loss in 5000th batch is: 8.053164\n","the loss in 5200th batch is: 8.341270\n","the loss in 5400th batch is: 8.050527\n","the loss in 5600th batch is: 7.863175\n","the loss in 5800th batch is: 7.949325\n","the loss in 6000th batch is: 8.100606\n","the loss in 6200th batch is: 7.969481\n","the loss in 6400th batch is: 7.621478\n","the loss in 6600th batch is: 8.027712\n","the loss in 6800th batch is: 7.836064\n","the loss in 7000th batch is: 7.625298\n","the loss in 7200th batch is: 7.209857\n","the loss in 7400th batch is: 7.358767\n","the loss in 7600th batch is: 7.033537\n","the loss in 7800th batch is: 7.244955\n","the loss in 8000th batch is: 7.251165\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 8088.400000\n","clicks hr ndcg @ 5 : 0.234494, 0.185189\n","purchase hr and ndcg @5 : 0.480060, 0.415205\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 9285.600000\n","clicks hr ndcg @ 10 : 0.275751, 0.198563\n","purchase hr and ndcg @10 : 0.521830, 0.428761\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 9970.400000\n","clicks hr ndcg @ 15 : 0.299283, 0.204797\n","purchase hr and ndcg @15 : 0.546022, 0.435169\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 10441.800000\n","clicks hr ndcg @ 20 : 0.315952, 0.208738\n","purchase hr and ndcg @20 : 0.560575, 0.438618\n","#############################################################\n","the loss in 8200th batch is: 7.109671\n","the loss in 8400th batch is: 7.311831\n","the loss in 8600th batch is: 6.896509\n","the loss in 8800th batch is: 6.779829\n","the loss in 9000th batch is: 6.983710\n","the loss in 9200th batch is: 7.054176\n","the loss in 9400th batch is: 6.536765\n","the loss in 9600th batch is: 6.615097\n","the loss in 9800th batch is: 7.069401\n","the loss in 10000th batch is: 6.540778\n","the loss in 10200th batch is: 7.102609\n","the loss in 10400th batch is: 6.714309\n","the loss in 10600th batch is: 6.761150\n","the loss in 10800th batch is: 6.709429\n","the loss in 11000th batch is: 6.814142\n","the loss in 11200th batch is: 6.625546\n","the loss in 11400th batch is: 6.471951\n","the loss in 11600th batch is: 6.486908\n","the loss in 11800th batch is: 6.332845\n","the loss in 12000th batch is: 6.082487\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 8728.400000\n","clicks hr ndcg @ 5 : 0.252709, 0.197976\n","purchase hr and ndcg @5 : 0.519562, 0.441127\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 10089.000000\n","clicks hr ndcg @ 10 : 0.299393, 0.213108\n","purchase hr and ndcg @10 : 0.567946, 0.456995\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 10828.800000\n","clicks hr ndcg @ 15 : 0.325715, 0.220076\n","purchase hr and ndcg @15 : 0.590059, 0.462850\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 11327.600000\n","clicks hr ndcg @ 20 : 0.343710, 0.224330\n","purchase hr and ndcg @20 : 0.603856, 0.466116\n","#############################################################\n","the loss in 12200th batch is: 6.380847\n","the loss in 12400th batch is: 6.255709\n","the loss in 12600th batch is: 6.551149\n","the loss in 12800th batch is: 6.301414\n","the loss in 13000th batch is: 6.062526\n","the loss in 13200th batch is: 6.659710\n","the loss in 13400th batch is: 6.338543\n","the loss in 13600th batch is: 5.856994\n","the loss in 13800th batch is: 6.102191\n","the loss in 14000th batch is: 6.479534\n","the loss in 14200th batch is: 6.298847\n","the loss in 14400th batch is: 6.161039\n","the loss in 14600th batch is: 5.753212\n","the loss in 14800th batch is: 5.895512\n","the loss in 15000th batch is: 6.121010\n","the loss in 15200th batch is: 6.268915\n","the loss in 15400th batch is: 6.112689\n","the loss in 15600th batch is: 5.741707\n","the loss in 15800th batch is: 6.256157\n","the loss in 16000th batch is: 5.979118\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 8962.000000\n","clicks hr ndcg @ 5 : 0.261356, 0.204301\n","purchase hr and ndcg @5 : 0.525043, 0.443097\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 10381.600000\n","clicks hr ndcg @ 10 : 0.309984, 0.220090\n","purchase hr and ndcg @10 : 0.575884, 0.459702\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 11153.800000\n","clicks hr ndcg @ 15 : 0.337337, 0.227342\n","purchase hr and ndcg @15 : 0.599509, 0.465949\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 11691.800000\n","clicks hr ndcg @ 20 : 0.356820, 0.231945\n","purchase hr and ndcg @20 : 0.614062, 0.469399\n","#############################################################\n","the loss in 16200th batch is: 5.305518\n","the loss in 16400th batch is: 6.068407\n","the loss in 16600th batch is: 5.644617\n","the loss in 16800th batch is: 5.730868\n","the loss in 17000th batch is: 6.041760\n","the loss in 17200th batch is: 5.777803\n","the loss in 17400th batch is: 6.186962\n","the loss in 17600th batch is: 6.131454\n","the loss in 17800th batch is: 6.203813\n","the loss in 18000th batch is: 5.954081\n","the loss in 18200th batch is: 6.031854\n","the loss in 18400th batch is: 5.897039\n","the loss in 18600th batch is: 5.793849\n","the loss in 18800th batch is: 5.512998\n","the loss in 19000th batch is: 5.706522\n","the loss in 19200th batch is: 6.016477\n"]}],"source":["# ! python SNQN_new.py --model=GRU --epoch=5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pBo8vQNGFVBb"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v5A0DThvFU_T"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rjSiyLDoFU9B"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qibeO_dXFUze"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"tbkHx7wrFVxO"},"source":["### With features"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7425,"status":"ok","timestamp":1699838683364,"user":{"displayName":"YUANJING ZHU","userId":"04814336122574376139"},"user_tz":300},"id":"osuf81unEzVF","outputId":"6f73115f-3231-4db8-8eb1-b39e3cf95cd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-11-13 01:24:36.137168: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-11-13 01:24:36.182625: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-13 01:24:36.182693: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-13 01:24:36.182753: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-13 01:24:36.191385: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-11-13 01:24:37.311404: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","INFO line 102:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 107:13: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n","INFO line 109:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 112:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","WARNING line 117:29: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","INFO line 122:46: Renamed 'tf.nn.dynamic_rnn' to 'tf.compat.v1.nn.dynamic_rnn'\n","INFO line 123:20: Renamed 'tf.contrib.rnn.GRUCell' to 'tf.compat.v1.nn.rnn_cell.GRUCell'\n","INFO line 131:20: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n","INFO line 142:25: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n","\n","INFO line 142:25: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n","INFO line 146:28: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n","INFO line 150:31: Added keywords to args of function 'tf.nn.conv2d'\n","INFO line 150:31: Renamed keyword argument for tf.nn.conv2d from filter to filters\n","INFO line 162:33: Added keywords to args of function 'tf.nn.max_pool'\n","INFO line 162:33: Renamed keyword argument for tf.nn.max_pool from value to input\n","INFO line 162:33: Renamed 'tf.nn.max_pool' to 'tf.nn.max_pool2d'\n","INFO line 178:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n","\n","INFO line 178:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n","INFO line 181:24: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n","INFO line 184:27: Added keywords to args of function 'tf.nn.conv2d'\n","INFO line 184:27: Renamed keyword argument for tf.nn.conv2d from filter to filters\n","INFO line 198:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n","\n","INFO line 198:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n","INFO line 199:41: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n","INFO line 206:20: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n","WARNING line 223:36: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","WARNING line 244:26: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","INFO line 254:20: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n","INFO line 257:27: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n","INFO line 267:25: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n","INFO line 313:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 315:36: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 317:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 318:37: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 321:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 322:28: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 324:36: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 325:44: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 361:23: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n","INFO line 366:17: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n","INFO line 368:20: Renamed 'tf.random_normal' to 'tf.random.normal'\n","INFO line 372:20: Renamed 'tf.random_normal' to 'tf.random.normal'\n","INFO line 490:4: Renamed 'tf.reset_default_graph' to 'tf.compat.v1.reset_default_graph'\n","INFO line 517:9: Renamed 'tf.Session' to 'tf.compat.v1.Session'\n","INFO line 519:17: Renamed 'tf.global_variables_initializer' to 'tf.compat.v1.global_variables_initializer'\n","TensorFlow 2.0 Upgrade Script\n","-----------------------------\n","Converted 1 files\n","Detected 3 issues that require attention\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","File: /content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features.py\n","--------------------------------------------------------------------------------\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features.py:117:29: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features.py:223:36: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features.py:244:26: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","\n","\n","Make sure to read the detailed log 'report_SNQN_with_Features.txt'\n","\n"]}],"source":["!tf_upgrade_v2 \\\n","  --infile '/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features.py' \\\n","  --outfile '/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py' \\\n","  --reportfile report_SNQN_with_Features.txt"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5445,"status":"ok","timestamp":1699838688796,"user":{"displayName":"YUANJING ZHU","userId":"04814336122574376139"},"user_tz":300},"id":"xxKrD60n4o0q","outputId":"5ef1613e-0ecf-4b00-bc1d-414d200e614f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: trfl in /usr/local/lib/python3.10/dist-packages (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n"]}],"source":["! pip install pandas trfl"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kqCNKCdbEzVG","executionInfo":{"status":"ok","timestamp":1699383805145,"user_tz":300,"elapsed":2764535,"user":{"displayName":"YUANJING ZHU","userId":"04814336122574376139"}},"outputId":"b4a653e6-065a-4cbd-f936-ac894214e430"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-11-07 14:33:13.755710: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-07 14:33:13.755772: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-07 14:33:13.755810: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-07 14:33:13.764116: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-11-07 14:33:15.324366: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:123: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n","  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n","WARNING:tensorflow:From /content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:122: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:292: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:296: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2 = tf.compat.v1.layers.dense(\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:300: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.w_fj = tf.compat.v1.layers.dense(\n","2023-11-07 14:33:38.900146: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 1.600000\n","clicks hr ndcg @ 5 : 0.000068, 0.000037\n","purchase hr and ndcg @5 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 3.600000\n","clicks hr ndcg @ 10 : 0.000152, 0.000064\n","purchase hr and ndcg @10 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 5.200000\n","clicks hr ndcg @ 15 : 0.000220, 0.000082\n","purchase hr and ndcg @15 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 6.400000\n","clicks hr ndcg @ 20 : 0.000270, 0.000094\n","purchase hr and ndcg @20 : 0.000000, 0.000000\n","#############################################################\n","the loss in 200th batch is: 10.666195\n","the loss in 400th batch is: 10.482259\n","the loss in 600th batch is: 10.428629\n","the loss in 800th batch is: 10.055241\n","the loss in 1000th batch is: 10.299025\n","the loss in 1200th batch is: 10.125604\n","the loss in 1400th batch is: 9.805387\n","the loss in 1600th batch is: 9.820959\n","the loss in 1800th batch is: 9.587521\n","the loss in 2000th batch is: 9.717780\n","the loss in 2200th batch is: 9.839053\n","the loss in 2400th batch is: 9.160925\n","the loss in 2600th batch is: 9.330402\n","the loss in 2800th batch is: 9.062589\n","the loss in 3000th batch is: 9.122049\n","the loss in 3200th batch is: 8.359146\n","the loss in 3400th batch is: 8.685285\n","the loss in 3600th batch is: 8.862950\n","the loss in 3800th batch is: 8.702549\n","the loss in 4000th batch is: 8.907609\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 4400.000000\n","clicks hr ndcg @ 5 : 0.125987, 0.095524\n","purchase hr and ndcg @5 : 0.268191, 0.213297\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 5304.000000\n","clicks hr ndcg @ 10 : 0.153923, 0.104552\n","purchase hr and ndcg @10 : 0.314118, 0.228262\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 5832.000000\n","clicks hr ndcg @ 15 : 0.171504, 0.109206\n","purchase hr and ndcg @15 : 0.335286, 0.233887\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 6238.200000\n","clicks hr ndcg @ 20 : 0.184065, 0.112174\n","purchase hr and ndcg @20 : 0.355887, 0.238769\n","#############################################################\n","the loss in 4200th batch is: 8.243044\n","the loss in 4400th batch is: 8.296969\n","the loss in 4600th batch is: 8.088463\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py\", line 597, in <module>\n","    loss, _ = sess.run(\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\", line 972, in run\n","    result = self._run(None, fetches, feed_dict, options_ptr,\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\", line 1215, in _run\n","    results = self._do_run(handle, final_targets, final_fetches,\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\", line 1395, in _do_run\n","    return self._do_call(_run_fn, feeds, fetches, targets, options,\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\", line 1402, in _do_call\n","    return fn(*args)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\", line 1385, in _run_fn\n","    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\", line 1478, in _call_tf_sessionrun\n","    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n","KeyboardInterrupt\n","^C\n"]}],"source":["! python SNQN_with_Features_new.py --model=GRU --epoch=5 --mixing_parameter=0.15"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0sWktUaBEzVG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"511e2be6-2cf8-47e9-c5da-47583d649213"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-11-08 22:33:43.144673: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-08 22:33:43.145363: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-08 22:33:43.145424: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-08 22:33:43.171958: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-11-08 22:33:46.085930: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:123: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n","  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n","WARNING:tensorflow:From /content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:122: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:292: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:296: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2 = tf.compat.v1.layers.dense(\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:300: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.w_fj = tf.compat.v1.layers.dense(\n","2023-11-08 22:34:07.039185: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 1.400000\n","clicks hr ndcg @ 5 : 0.000059, 0.000033\n","purchase hr and ndcg @5 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 3.400000\n","clicks hr ndcg @ 10 : 0.000101, 0.000045\n","purchase hr and ndcg @10 : 0.000189, 0.000057\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 4.600000\n","clicks hr ndcg @ 15 : 0.000152, 0.000059\n","purchase hr and ndcg @15 : 0.000189, 0.000057\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 6.800000\n","clicks hr ndcg @ 20 : 0.000245, 0.000081\n","purchase hr and ndcg @20 : 0.000189, 0.000057\n","#############################################################\n","the loss in 200th batch is: 10.776367\n","the loss in 400th batch is: 10.681171\n","the loss in 600th batch is: 10.403624\n","the loss in 800th batch is: 10.174244\n","the loss in 1000th batch is: 10.239595\n","the loss in 1200th batch is: 10.096027\n","the loss in 1400th batch is: 9.810034\n","the loss in 1600th batch is: 9.947531\n","the loss in 1800th batch is: 9.424160\n","the loss in 2000th batch is: 9.615074\n","the loss in 2200th batch is: 9.388897\n","the loss in 2400th batch is: 9.035999\n","the loss in 2600th batch is: 8.923826\n","the loss in 2800th batch is: 9.169666\n","the loss in 3000th batch is: 8.865185\n","the loss in 3200th batch is: 9.340988\n","the loss in 3400th batch is: 8.879235\n","the loss in 3600th batch is: 8.602638\n","the loss in 3800th batch is: 8.442808\n","the loss in 4000th batch is: 8.777401\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 3949.000000\n","clicks hr ndcg @ 5 : 0.111744, 0.083631\n","purchase hr and ndcg @5 : 0.246645, 0.191509\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 4869.400000\n","clicks hr ndcg @ 10 : 0.140838, 0.093036\n","purchase hr and ndcg @10 : 0.290493, 0.205690\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 5437.600000\n","clicks hr ndcg @ 15 : 0.159020, 0.097839\n","purchase hr and ndcg @15 : 0.316575, 0.212613\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 5843.800000\n","clicks hr ndcg @ 20 : 0.172383, 0.100995\n","purchase hr and ndcg @20 : 0.333585, 0.216652\n","#############################################################\n","the loss in 4200th batch is: 8.132944\n","the loss in 4400th batch is: 8.190144\n","the loss in 4600th batch is: 8.622916\n","the loss in 4800th batch is: 8.313999\n","the loss in 5000th batch is: 8.273567\n","the loss in 5200th batch is: 8.055062\n","the loss in 5400th batch is: 8.436131\n","the loss in 5600th batch is: 8.198750\n","the loss in 5800th batch is: 8.152081\n","the loss in 6000th batch is: 8.170050\n","the loss in 6200th batch is: 7.815216\n","the loss in 6400th batch is: 7.873287\n","the loss in 6600th batch is: 7.676316\n","the loss in 6800th batch is: 7.819469\n"]}],"source":["! python SNQN_with_Features_new.py --model=GRU --epoch=5 --mixing_parameter=0.25"]},{"cell_type":"code","source":["! python SNQN_with_Features_new.py --model=GRU --epoch=5 --mixing_parameter=0.5"],"metadata":{"id":"d2CuUillKyAO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"34759d39-69d2-44bb-9a4e-3c385cf6fb2c","executionInfo":{"status":"ok","timestamp":1699900302752,"user_tz":300,"elapsed":6459571,"user":{"displayName":"YUANJING ZHU","userId":"04814336122574376139"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-11-13 16:44:04.143592: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-13 16:44:04.143639: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-13 16:44:04.143663: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-13 16:44:04.150685: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-11-13 16:44:05.164326: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:123: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n","  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n","WARNING:tensorflow:From /content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:122: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","2023-11-13 16:44:11.399276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-13 16:44:12.033281: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-13 16:44:12.033528: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-13 16:44:12.035025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-13 16:44:12.035259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-13 16:44:12.035413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-13 16:44:14.616042: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-13 16:44:14.616292: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-13 16:44:14.616406: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-11-13 16:44:14.616458: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-13 16:44:14.616569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14582 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:292: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:296: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2 = tf.compat.v1.layers.dense(\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:300: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.w_fj = tf.compat.v1.layers.dense(\n","2023-11-13 16:44:22.220077: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-13 16:44:22.220416: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-13 16:44:22.220577: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-13 16:44:22.220775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-13 16:44:22.220926: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-11-13 16:44:22.221055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14582 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n","2023-11-13 16:44:22.748842: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 0.800000\n","clicks hr ndcg @ 5 : 0.000034, 0.000024\n","purchase hr and ndcg @5 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 3.600000\n","clicks hr ndcg @ 10 : 0.000110, 0.000048\n","purchase hr and ndcg @10 : 0.000189, 0.000063\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 4.000000\n","clicks hr ndcg @ 15 : 0.000127, 0.000052\n","purchase hr and ndcg @15 : 0.000189, 0.000063\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 6.000000\n","clicks hr ndcg @ 20 : 0.000169, 0.000062\n","purchase hr and ndcg @20 : 0.000378, 0.000106\n","#############################################################\n","the loss in 200th batch is: 10.952182\n","the loss in 400th batch is: 10.597521\n","the loss in 600th batch is: 10.261021\n","the loss in 800th batch is: 10.336411\n","the loss in 1000th batch is: 10.146792\n","the loss in 1200th batch is: 9.836756\n","the loss in 1400th batch is: 9.794647\n","the loss in 1600th batch is: 9.680783\n","the loss in 1800th batch is: 9.470591\n","the loss in 2000th batch is: 9.725861\n","the loss in 2200th batch is: 9.305276\n","the loss in 2400th batch is: 9.626560\n","the loss in 2600th batch is: 9.250412\n","the loss in 2800th batch is: 9.243589\n","the loss in 3000th batch is: 9.222683\n","the loss in 3200th batch is: 8.900473\n","the loss in 3400th batch is: 8.500755\n","the loss in 3600th batch is: 9.052876\n","the loss in 3800th batch is: 8.838732\n","the loss in 4000th batch is: 8.589371\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 2600.400000\n","clicks hr ndcg @ 5 : 0.074569, 0.052983\n","purchase hr and ndcg @5 : 0.158004, 0.120229\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 3372.800000\n","clicks hr ndcg @ 10 : 0.098423, 0.060683\n","purchase hr and ndcg @10 : 0.197316, 0.133053\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 3832.200000\n","clicks hr ndcg @ 15 : 0.113147, 0.064573\n","purchase hr and ndcg @15 : 0.218295, 0.138592\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 4191.800000\n","clicks hr ndcg @ 20 : 0.124837, 0.067334\n","purchase hr and ndcg @20 : 0.233982, 0.142297\n","#############################################################\n","the loss in 4200th batch is: 8.918128\n","the loss in 4400th batch is: 8.485678\n","the loss in 4600th batch is: 8.627237\n","the loss in 4800th batch is: 8.247326\n","the loss in 5000th batch is: 8.486877\n","the loss in 5200th batch is: 8.086306\n","the loss in 5400th batch is: 8.353801\n","the loss in 5600th batch is: 8.329269\n","the loss in 5800th batch is: 7.929469\n","the loss in 6000th batch is: 7.851446\n","the loss in 6200th batch is: 7.900731\n","the loss in 6400th batch is: 8.170915\n","the loss in 6600th batch is: 8.089586\n","the loss in 6800th batch is: 7.582340\n","the loss in 7000th batch is: 8.237169\n","the loss in 7200th batch is: 7.643649\n","the loss in 7400th batch is: 7.775215\n","the loss in 7600th batch is: 7.680547\n","the loss in 7800th batch is: 7.620679\n","the loss in 8000th batch is: 7.611913\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 3757.200000\n","clicks hr ndcg @ 5 : 0.109808, 0.079215\n","purchase hr and ndcg @5 : 0.219051, 0.166619\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 4861.400000\n","clicks hr ndcg @ 10 : 0.144642, 0.090478\n","purchase hr and ndcg @10 : 0.271971, 0.183741\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 5543.400000\n","clicks hr ndcg @ 15 : 0.165647, 0.096035\n","purchase hr and ndcg @15 : 0.306936, 0.192977\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 6086.800000\n","clicks hr ndcg @ 20 : 0.182442, 0.100005\n","purchase hr and ndcg @20 : 0.334530, 0.199516\n","#############################################################\n","the loss in 8200th batch is: 7.642284\n","the loss in 8400th batch is: 7.900737\n","the loss in 8600th batch is: 7.402862\n","the loss in 8800th batch is: 7.696958\n","the loss in 9000th batch is: 7.336543\n","the loss in 9200th batch is: 7.200112\n","the loss in 9400th batch is: 7.167760\n","the loss in 9600th batch is: 7.267001\n","the loss in 9800th batch is: 7.162078\n","the loss in 10000th batch is: 7.122954\n","the loss in 10200th batch is: 7.156067\n","the loss in 10400th batch is: 7.336522\n","the loss in 10600th batch is: 7.148874\n","the loss in 10800th batch is: 7.637827\n","the loss in 11000th batch is: 7.301511\n","the loss in 11200th batch is: 6.752951\n","the loss in 11400th batch is: 7.400579\n","the loss in 11600th batch is: 7.577385\n","the loss in 11800th batch is: 7.067804\n","the loss in 12000th batch is: 6.817475\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 4321.000000\n","clicks hr ndcg @ 5 : 0.126283, 0.091023\n","purchase hr and ndcg @5 : 0.251937, 0.186789\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 5653.600000\n","clicks hr ndcg @ 10 : 0.168402, 0.104590\n","purchase hr and ndcg @10 : 0.315441, 0.207306\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 6540.800000\n","clicks hr ndcg @ 15 : 0.195121, 0.111657\n","purchase hr and ndcg @15 : 0.363636, 0.220038\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 7139.400000\n","clicks hr ndcg @ 20 : 0.214503, 0.116235\n","purchase hr and ndcg @20 : 0.390096, 0.226281\n","#############################################################\n","the loss in 12200th batch is: 7.011293\n","the loss in 12400th batch is: 6.558400\n","the loss in 12600th batch is: 7.162008\n","the loss in 12800th batch is: 6.585174\n","the loss in 13000th batch is: 6.642882\n","the loss in 13200th batch is: 6.421010\n","the loss in 13400th batch is: 7.006310\n","the loss in 13600th batch is: 6.728682\n","the loss in 13800th batch is: 6.919836\n","the loss in 14000th batch is: 6.807904\n","the loss in 14200th batch is: 6.431829\n","the loss in 14400th batch is: 6.763176\n","the loss in 14600th batch is: 6.590750\n","the loss in 14800th batch is: 6.736959\n","the loss in 15000th batch is: 6.753179\n","the loss in 15200th batch is: 6.324941\n","the loss in 15400th batch is: 7.150595\n","the loss in 15600th batch is: 6.433619\n","the loss in 15800th batch is: 6.620404\n","the loss in 16000th batch is: 6.961507\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 4645.000000\n","clicks hr ndcg @ 5 : 0.134651, 0.096862\n","purchase hr and ndcg @5 : 0.275751, 0.206970\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 6098.400000\n","clicks hr ndcg @ 10 : 0.181031, 0.111832\n","purchase hr and ndcg @10 : 0.343035, 0.228716\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 7002.000000\n","clicks hr ndcg @ 15 : 0.210598, 0.119657\n","purchase hr and ndcg @15 : 0.381591, 0.238890\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 7657.000000\n","clicks hr ndcg @ 20 : 0.232110, 0.124737\n","purchase hr and ndcg @20 : 0.409185, 0.245411\n","#############################################################\n","the loss in 16200th batch is: 6.815681\n","the loss in 16400th batch is: 6.449300\n","the loss in 16600th batch is: 6.093234\n","the loss in 16800th batch is: 6.726699\n","the loss in 17000th batch is: 6.097238\n","the loss in 17200th batch is: 6.313395\n","the loss in 17400th batch is: 6.301687\n","the loss in 17600th batch is: 6.305257\n","the loss in 17800th batch is: 6.398811\n","the loss in 18000th batch is: 6.745254\n","the loss in 18200th batch is: 6.627015\n","the loss in 18400th batch is: 6.917966\n","the loss in 18600th batch is: 6.482055\n","the loss in 18800th batch is: 6.605904\n","the loss in 19000th batch is: 6.558588\n","the loss in 19200th batch is: 6.381013\n"]}]},{"cell_type":"code","source":["! python SNQN_with_Features_new.py --model=GRU --epoch=5 --mixing_parameter=0.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uIu34eJapon-","outputId":"5486e2e4-3fa6-4045-e010-6ef623608745","executionInfo":{"status":"ok","timestamp":1699845591407,"user_tz":300,"elapsed":6895991,"user":{"displayName":"YUANJING ZHU","userId":"04814336122574376139"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-11-13 01:24:55.637651: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-11-13 01:24:55.681714: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-13 01:24:55.681760: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-13 01:24:55.681802: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-13 01:24:55.690065: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-11-13 01:24:56.828480: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:123: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n","  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n","WARNING:tensorflow:From /content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:122: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","2023-11-13 01:25:03.665921: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-11-13 01:25:03.666097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38350 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:292: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:296: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2 = tf.compat.v1.layers.dense(\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:300: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.w_fj = tf.compat.v1.layers.dense(\n","2023-11-13 01:25:10.730407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38350 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n","2023-11-13 01:25:11.266741: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 1.200000\n","clicks hr ndcg @ 5 : 0.000051, 0.000028\n","purchase hr and ndcg @5 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 2.800000\n","clicks hr ndcg @ 10 : 0.000118, 0.000050\n","purchase hr and ndcg @10 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 4.800000\n","clicks hr ndcg @ 15 : 0.000203, 0.000072\n","purchase hr and ndcg @15 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 6.000000\n","clicks hr ndcg @ 20 : 0.000254, 0.000084\n","purchase hr and ndcg @20 : 0.000000, 0.000000\n","#############################################################\n","the loss in 200th batch is: 10.742290\n","the loss in 400th batch is: 10.495011\n","the loss in 600th batch is: 10.343449\n","the loss in 800th batch is: 10.465261\n","the loss in 1000th batch is: 10.194634\n","the loss in 1200th batch is: 9.965986\n","the loss in 1400th batch is: 9.891745\n","the loss in 1600th batch is: 9.601984\n","the loss in 1800th batch is: 9.693377\n","the loss in 2000th batch is: 9.549969\n","the loss in 2200th batch is: 9.246776\n","the loss in 2400th batch is: 9.269073\n","the loss in 2600th batch is: 9.623504\n","the loss in 2800th batch is: 9.046465\n","the loss in 3000th batch is: 8.673418\n","the loss in 3200th batch is: 8.827602\n","the loss in 3400th batch is: 8.538676\n","the loss in 3600th batch is: 8.594923\n","the loss in 3800th batch is: 8.967341\n","the loss in 4000th batch is: 8.714681\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 4229.200000\n","clicks hr ndcg @ 5 : 0.119360, 0.088705\n","purchase hr and ndcg @5 : 0.265545, 0.209406\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 5147.200000\n","clicks hr ndcg @ 10 : 0.149071, 0.098329\n","purchase hr and ndcg @10 : 0.306180, 0.222510\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 5711.400000\n","clicks hr ndcg @ 15 : 0.167210, 0.103131\n","purchase hr and ndcg @15 : 0.331695, 0.229276\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 6132.400000\n","clicks hr ndcg @ 20 : 0.181073, 0.106409\n","purchase hr and ndcg @20 : 0.349272, 0.233444\n","#############################################################\n","the loss in 4200th batch is: 8.539367\n","the loss in 4400th batch is: 8.485205\n","the loss in 4600th batch is: 8.451346\n","the loss in 4800th batch is: 8.311950\n","the loss in 5000th batch is: 8.261954\n","the loss in 5200th batch is: 8.380200\n","the loss in 5400th batch is: 8.334303\n","the loss in 5600th batch is: 7.739569\n","the loss in 5800th batch is: 8.093133\n","the loss in 6000th batch is: 7.403279\n","the loss in 6200th batch is: 7.902942\n","the loss in 6400th batch is: 8.082316\n","the loss in 6600th batch is: 7.448566\n","the loss in 6800th batch is: 7.930743\n","the loss in 7000th batch is: 7.920336\n","the loss in 7200th batch is: 7.788705\n","the loss in 7400th batch is: 7.557611\n","the loss in 7600th batch is: 7.389024\n","the loss in 7800th batch is: 7.103736\n","the loss in 8000th batch is: 7.407420\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 5834.600000\n","clicks hr ndcg @ 5 : 0.169501, 0.125689\n","purchase hr and ndcg @5 : 0.344736, 0.271259\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 7177.200000\n","clicks hr ndcg @ 10 : 0.212846, 0.139706\n","purchase hr and ndcg @10 : 0.404649, 0.290678\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 7970.800000\n","clicks hr ndcg @ 15 : 0.238399, 0.146470\n","purchase hr and ndcg @15 : 0.440370, 0.300092\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 8509.200000\n","clicks hr ndcg @ 20 : 0.256335, 0.150707\n","purchase hr and ndcg @20 : 0.461916, 0.305182\n","#############################################################\n","the loss in 8200th batch is: 7.339985\n","the loss in 8400th batch is: 7.132232\n","the loss in 8600th batch is: 7.077706\n","the loss in 8800th batch is: 7.169334\n","the loss in 9000th batch is: 7.433184\n","the loss in 9200th batch is: 7.356123\n","the loss in 9400th batch is: 7.199457\n","the loss in 9600th batch is: 6.710996\n","the loss in 9800th batch is: 7.247433\n","the loss in 10000th batch is: 6.696795\n","the loss in 10200th batch is: 6.950799\n","the loss in 10400th batch is: 6.520461\n","the loss in 10600th batch is: 6.868386\n","the loss in 10800th batch is: 6.405628\n","the loss in 11000th batch is: 6.833576\n","the loss in 11200th batch is: 6.606693\n","the loss in 11400th batch is: 6.803535\n","the loss in 11600th batch is: 6.576900\n","the loss in 11800th batch is: 6.846268\n","the loss in 12000th batch is: 6.085217\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 6388.600000\n","clicks hr ndcg @ 5 : 0.186364, 0.137775\n","purchase hr and ndcg @5 : 0.374031, 0.294163\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 7905.000000\n","clicks hr ndcg @ 10 : 0.234603, 0.153351\n","purchase hr and ndcg @10 : 0.444906, 0.317253\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 8828.800000\n","clicks hr ndcg @ 15 : 0.264771, 0.161351\n","purchase hr and ndcg @15 : 0.484596, 0.327764\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 9418.000000\n","clicks hr ndcg @ 20 : 0.284643, 0.166043\n","purchase hr and ndcg @20 : 0.507088, 0.333062\n","#############################################################\n","the loss in 12200th batch is: 6.642571\n","the loss in 12400th batch is: 6.422799\n","the loss in 12600th batch is: 6.682443\n","the loss in 12800th batch is: 6.680218\n","the loss in 13000th batch is: 6.324607\n","the loss in 13200th batch is: 6.229463\n","the loss in 13400th batch is: 6.151431\n","the loss in 13600th batch is: 6.282925\n","the loss in 13800th batch is: 6.560841\n","the loss in 14000th batch is: 6.537978\n","the loss in 14200th batch is: 6.450562\n","the loss in 14400th batch is: 7.053103\n","the loss in 14600th batch is: 6.447163\n","the loss in 14800th batch is: 6.188917\n","the loss in 15000th batch is: 6.343729\n","the loss in 15200th batch is: 6.146358\n","the loss in 15400th batch is: 5.586821\n","the loss in 15600th batch is: 6.092854\n","the loss in 15800th batch is: 6.545894\n","the loss in 16000th batch is: 6.456788\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 6588.000000\n","clicks hr ndcg @ 5 : 0.192171, 0.142475\n","purchase hr and ndcg @5 : 0.385749, 0.304512\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 8243.400000\n","clicks hr ndcg @ 10 : 0.245651, 0.159762\n","purchase hr and ndcg @10 : 0.459459, 0.328336\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 9203.200000\n","clicks hr ndcg @ 15 : 0.277636, 0.168226\n","purchase hr and ndcg @15 : 0.497826, 0.338469\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 9830.800000\n","clicks hr ndcg @ 20 : 0.298370, 0.173127\n","purchase hr and ndcg @20 : 0.523720, 0.344569\n","#############################################################\n","the loss in 16200th batch is: 6.084204\n","the loss in 16400th batch is: 6.488800\n","the loss in 16600th batch is: 6.112723\n","the loss in 16800th batch is: 6.426861\n","the loss in 17000th batch is: 6.168214\n","the loss in 17200th batch is: 6.030295\n","the loss in 17400th batch is: 6.039690\n","the loss in 17600th batch is: 5.908453\n","the loss in 17800th batch is: 6.077766\n","the loss in 18000th batch is: 5.861841\n","the loss in 18200th batch is: 5.902404\n","the loss in 18400th batch is: 6.074251\n","the loss in 18600th batch is: 5.825814\n","the loss in 18800th batch is: 6.457645\n","the loss in 19000th batch is: 6.137978\n","the loss in 19200th batch is: 5.693869\n"]}]},{"cell_type":"code","source":["! python SNQN_with_Features_new.py --model=GRU --epoch=5 --mixing_parameter=0.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OD6F6mwXwUNh","outputId":"bcc5c1d1-7fa5-404c-cbe3-84d9ac46735d","executionInfo":{"status":"ok","timestamp":1699852837216,"user_tz":300,"elapsed":370801,"user":{"displayName":"YUANJING ZHU","userId":"04814336122574376139"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-11-13 03:27:57.541499: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-11-13 03:27:57.587156: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-13 03:27:57.587212: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-13 03:27:57.587252: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-13 03:27:57.595883: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-11-13 03:27:58.730084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:123: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n","  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n","WARNING:tensorflow:From /content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:122: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","2023-11-13 03:28:03.415395: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-11-13 03:28:03.415603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38350 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:292: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:296: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2 = tf.compat.v1.layers.dense(\n","/content/drive/MyDrive/MIDS/AIPI_531/HW_3/SA2C_code/Kaggle/SNQN_with_Features_new.py:300: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.w_fj = tf.compat.v1.layers.dense(\n","2023-11-13 03:28:10.487440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38350 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n","2023-11-13 03:28:11.020551: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 2.600000\n","clicks hr ndcg @ 5 : 0.000025, 0.000015\n","purchase hr and ndcg @5 : 0.000378, 0.000262\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 4.600000\n","clicks hr ndcg @ 10 : 0.000110, 0.000043\n","purchase hr and ndcg @10 : 0.000378, 0.000262\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 5.200000\n","clicks hr ndcg @ 15 : 0.000135, 0.000049\n","purchase hr and ndcg @15 : 0.000378, 0.000262\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 7.000000\n","clicks hr ndcg @ 20 : 0.000169, 0.000058\n","purchase hr and ndcg @20 : 0.000567, 0.000307\n","#############################################################\n","the loss in 200th batch is: 10.810007\n","the loss in 400th batch is: 10.608110\n","the loss in 600th batch is: 10.341421\n","the loss in 800th batch is: 10.389102\n","the loss in 1000th batch is: 10.259033\n","the loss in 1200th batch is: 10.186128\n","the loss in 1400th batch is: 9.867862\n","the loss in 1600th batch is: 9.781584\n","the loss in 1800th batch is: 9.838820\n","the loss in 2000th batch is: 9.844124\n","the loss in 2200th batch is: 9.333452\n","the loss in 2400th batch is: 9.271451\n","the loss in 2600th batch is: 9.393151\n","the loss in 2800th batch is: 9.119230\n","the loss in 3000th batch is: 9.365984\n","the loss in 3200th batch is: 8.791110\n","the loss in 3400th batch is: 8.779542\n","the loss in 3600th batch is: 8.292346\n","the loss in 3800th batch is: 8.809675\n","the loss in 4000th batch is: 8.656547\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 5973.800000\n","clicks hr ndcg @ 5 : 0.170270, 0.135346\n","purchase hr and ndcg @5 : 0.367605, 0.316057\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 6842.000000\n","clicks hr ndcg @ 10 : 0.200412, 0.145095\n","purchase hr and ndcg @10 : 0.396900, 0.325500\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 7403.800000\n","clicks hr ndcg @ 15 : 0.219169, 0.150064\n","purchase hr and ndcg @15 : 0.419202, 0.331449\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 7771.200000\n","clicks hr ndcg @ 20 : 0.232034, 0.153101\n","purchase hr and ndcg @20 : 0.431109, 0.334266\n","#############################################################\n","the loss in 4200th batch is: 8.587531\n","the loss in 4400th batch is: 8.369679\n","the loss in 4600th batch is: 8.089876\n","the loss in 4800th batch is: 8.070818\n","the loss in 5000th batch is: 8.564459\n","the loss in 5200th batch is: 8.407671\n","the loss in 5400th batch is: 8.103482\n","the loss in 5600th batch is: 7.942533\n","the loss in 5800th batch is: 7.612238\n","the loss in 6000th batch is: 7.857626\n","the loss in 6200th batch is: 8.168201\n","the loss in 6400th batch is: 7.541370\n","the loss in 6600th batch is: 8.087090\n","the loss in 6800th batch is: 7.577105\n","the loss in 7000th batch is: 7.192233\n","the loss in 7200th batch is: 7.628509\n","the loss in 7400th batch is: 7.156766\n","the loss in 7600th batch is: 7.311171\n","the loss in 7800th batch is: 7.348579\n","the loss in 8000th batch is: 7.254671\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 8128.200000\n","clicks hr ndcg @ 5 : 0.235499, 0.185531\n","purchase hr and ndcg @5 : 0.483084, 0.411589\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 9394.800000\n","clicks hr ndcg @ 10 : 0.278591, 0.199464\n","purchase hr and ndcg @10 : 0.529768, 0.426791\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 10048.000000\n","clicks hr ndcg @ 15 : 0.301633, 0.205571\n","purchase hr and ndcg @15 : 0.550180, 0.432201\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 10501.400000\n","clicks hr ndcg @ 20 : 0.317921, 0.209418\n","purchase hr and ndcg @20 : 0.563032, 0.435244\n","#############################################################\n","the loss in 8200th batch is: 7.050498\n","the loss in 8400th batch is: 7.046324\n","the loss in 8600th batch is: 6.736275\n","the loss in 8800th batch is: 7.177629\n","the loss in 9000th batch is: 6.894746\n","the loss in 9200th batch is: 6.819032\n","the loss in 9400th batch is: 6.879718\n","the loss in 9600th batch is: 6.822433\n","the loss in 9800th batch is: 6.817633\n","the loss in 10000th batch is: 6.655560\n","the loss in 10200th batch is: 6.648120\n","the loss in 10400th batch is: 7.140686\n","the loss in 10600th batch is: 6.327821\n","the loss in 10800th batch is: 6.858807\n","the loss in 11000th batch is: 6.825162\n","the loss in 11200th batch is: 6.731189\n","the loss in 11400th batch is: 6.313375\n","the loss in 11600th batch is: 6.443195\n","the loss in 11800th batch is: 5.621830\n","the loss in 12000th batch is: 6.491896\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 8741.600000\n","clicks hr ndcg @ 5 : 0.254070, 0.199115\n","purchase hr and ndcg @5 : 0.515971, 0.437049\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 10134.800000\n","clicks hr ndcg @ 10 : 0.301751, 0.214577\n","purchase hr and ndcg @10 : 0.566056, 0.453262\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 10891.400000\n","clicks hr ndcg @ 15 : 0.328445, 0.221652\n","purchase hr and ndcg @15 : 0.589681, 0.459535\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 11383.800000\n","clicks hr ndcg @ 20 : 0.346381, 0.225892\n","purchase hr and ndcg @20 : 0.602533, 0.462566\n","#############################################################\n","the loss in 12200th batch is: 6.741193\n","the loss in 12400th batch is: 6.506995\n","the loss in 12600th batch is: 6.429118\n","the loss in 12800th batch is: 6.325145\n","the loss in 13000th batch is: 6.432841\n","the loss in 13200th batch is: 6.121682\n","the loss in 13400th batch is: 6.369987\n","the loss in 13600th batch is: 6.345404\n","the loss in 13800th batch is: 6.242816\n","the loss in 14000th batch is: 6.084234\n","the loss in 14200th batch is: 6.078089\n","the loss in 14400th batch is: 6.242996\n","the loss in 14600th batch is: 5.639197\n","the loss in 14800th batch is: 6.166262\n","the loss in 15000th batch is: 6.344641\n","the loss in 15200th batch is: 6.417693\n","the loss in 15400th batch is: 5.925292\n","the loss in 15600th batch is: 5.992109\n","the loss in 15800th batch is: 6.316939\n","the loss in 16000th batch is: 5.927118\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 8980.200000\n","clicks hr ndcg @ 5 : 0.261872, 0.204696\n","purchase hr and ndcg @5 : 0.526177, 0.442446\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 10409.200000\n","clicks hr ndcg @ 10 : 0.310982, 0.220612\n","purchase hr and ndcg @10 : 0.576640, 0.458825\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 11156.400000\n","clicks hr ndcg @ 15 : 0.337574, 0.227661\n","purchase hr and ndcg @15 : 0.598942, 0.464717\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 11696.800000\n","clicks hr ndcg @ 20 : 0.357116, 0.232285\n","purchase hr and ndcg @20 : 0.613684, 0.468207\n","#############################################################\n","the loss in 16200th batch is: 6.153524\n","the loss in 16400th batch is: 6.096788\n","the loss in 16600th batch is: 6.120409\n","the loss in 16800th batch is: 6.043736\n","the loss in 17000th batch is: 6.185491\n","the loss in 17200th batch is: 6.163707\n","the loss in 17400th batch is: 5.840874\n","the loss in 17600th batch is: 5.984195\n","the loss in 17800th batch is: 6.109406\n","the loss in 18000th batch is: 6.089756\n","the loss in 18200th batch is: 6.039512\n","the loss in 18400th batch is: 5.886945\n","the loss in 18600th batch is: 5.656693\n","the loss in 18800th batch is: 5.691568\n","the loss in 19000th batch is: 5.680848\n","the loss in 19200th batch is: 6.036633\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"MResu64p6D9Z"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}